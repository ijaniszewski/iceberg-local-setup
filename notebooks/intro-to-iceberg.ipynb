{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cabc966-dc04-4d1b-92af-b4de1324dab4",
   "metadata": {},
   "source": [
    "### MinIO explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6925cf3-92dc-4185-9ee7-53fc56bed26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '184A2C598E883D20',\n",
       "  'HostId': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'accept-ranges': 'bytes',\n",
       "   'content-length': '0',\n",
       "   'etag': '\"3af42309382afb590d9143564b4bb8b8\"',\n",
       "   'server': 'MinIO',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'vary': 'Origin, Accept-Encoding',\n",
       "   'x-amz-checksum-crc32': 'fW13PQ==',\n",
       "   'x-amz-id-2': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "   'x-amz-request-id': '184A2C598E883D20',\n",
       "   'x-content-type-options': 'nosniff',\n",
       "   'x-ratelimit-limit': '758',\n",
       "   'x-ratelimit-remaining': '758',\n",
       "   'x-xss-protection': '1; mode=block',\n",
       "   'date': 'Wed, 18 Jun 2025 15:22:48 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"3af42309382afb590d9143564b4bb8b8\"',\n",
       " 'ChecksumCRC32': 'fW13PQ=='}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# These come from your docker-compose env vars\n",
    "aws_access_key_id = os.environ[\"AWS_ACCESS_KEY_ID\"]     # \"admin\"\n",
    "aws_secret_access_key = os.environ[\"AWS_SECRET_ACCESS_KEY\"]  # \"password\"\n",
    "aws_region = os.environ[\"AWS_REGION\"] # us-east-1\n",
    "\n",
    "# Mocked S3 client that connects to local MinIO\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://minio:9000\",  # Local MinIO service\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=aws_region\n",
    ")\n",
    "\n",
    "# Create a bucket\n",
    "s3.create_bucket(Bucket=\"poc\")\n",
    "\n",
    "# Create a blob (upload a file)\n",
    "s3.put_object(Bucket=\"poc\", Key=\"demo.txt\", Body=b\"Hello, Iceberg!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5fb31f-d2ae-4f1a-b2ab-06611db6f71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found object: demo.txt\n"
     ]
    }
   ],
   "source": [
    "# List all the blobs\n",
    "\n",
    "response = s3.list_objects_v2(Bucket=\"poc\")\n",
    "for obj in response.get(\"Contents\", []):\n",
    "    print(f\"Found object: {obj['Key']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "062b77f6-284d-4710-b1f1-051945aec80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Iceberg!\n"
     ]
    }
   ],
   "source": [
    "# Read the blob\n",
    "\n",
    "response = s3.get_object(Bucket=\"poc\", Key=\"demo.txt\")\n",
    "print(response[\"Body\"].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03613e3a-8759-4993-afaf-debb3268a1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '184A2C5CF7B583B5',\n",
       "  'HostId': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "  'HTTPStatusCode': 204,\n",
       "  'HTTPHeaders': {'accept-ranges': 'bytes',\n",
       "   'server': 'MinIO',\n",
       "   'strict-transport-security': 'max-age=31536000; includeSubDomains',\n",
       "   'vary': 'Origin, Accept-Encoding',\n",
       "   'x-amz-id-2': 'dd9025bab4ad464b049177c95eb6ebf374d3b3fd1af9251148b658df7ac2e3e8',\n",
       "   'x-amz-request-id': '184A2C5CF7B583B5',\n",
       "   'x-content-type-options': 'nosniff',\n",
       "   'x-ratelimit-limit': '758',\n",
       "   'x-ratelimit-remaining': '758',\n",
       "   'x-xss-protection': '1; mode=block',\n",
       "   'date': 'Wed, 18 Jun 2025 15:23:02 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean it up\n",
    "\n",
    "# Delete blob\n",
    "s3.delete_object(Bucket=\"poc\", Key=\"demo.txt\")\n",
    "\n",
    "# Delete bucket\n",
    "s3.delete_bucket(Bucket=\"poc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21232b4-f564-41e1-8c0a-07b977a09071",
   "metadata": {},
   "source": [
    "### Iceberg time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8846fe4-3520-495b-b03f-1a754684bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "from pyiceberg.catalog import load_rest\n",
    "from pyiceberg.exceptions import NamespaceAlreadyExistsError, TableAlreadyExistsError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1371524-5cd3-4000-b685-ba596a03cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "from pyiceberg.catalog import load_rest\n",
    "from pyiceberg.exceptions import NamespaceAlreadyExistsError, TableAlreadyExistsError\n",
    "\n",
    "catalog = load_rest(\n",
    "    name=\"rest\",\n",
    "    conf = {\n",
    "        \"uri\": \"http://rest:8181/\",\n",
    "        \"s3.endpoint\": \"http://minio:9000\",\n",
    "        \"s3.access-key\": aws_access_key_id,\n",
    "        \"s3.secret-key\": aws_secret_access_key\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f406b19a-ba89-4dbe-bda1-dd3d83a428e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.exceptions import NamespaceAlreadyExistsError\n",
    "\n",
    "namespace = \"rideshare\"\n",
    "\n",
    "try:\n",
    "    catalog.create_namespace(namespace)\n",
    "except NamespaceAlreadyExistsError:\n",
    "    pass  # It's fine if it already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deec08c7-d43f-490c-9837-de73f497eb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespaces: [('rideshare',)]\n"
     ]
    }
   ],
   "source": [
    "namespaces = catalog.list_namespaces()\n",
    "print(\"Namespaces:\", namespaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "defddb68-d600-48f9-9da0-2c66f59b7866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, imports\n",
    "from pyiceberg.catalog import load_catalog\n",
    "from pyiceberg.exceptions import NamespaceAlreadyExistsError\n",
    "from pyiceberg.schema import Schema\n",
    "from pyiceberg.table import TableIdentifier\n",
    "from pyiceberg.partitioning import PartitionSpec\n",
    "from pyiceberg.types import UUIDType, StringType, TimestampType, DoubleType, NestedField, BooleanType, IntegerType, DecimalType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9d9c063-65e9-4a93-9fa2-204f4d938210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rides(\n",
       "  1: ride_id: required uuid,\n",
       "  2: driver_id: optional string,\n",
       "  3: customer_id: optional string,\n",
       "  4: pickup_time: optional timestamp,\n",
       "  5: dropoff_time: optional timestamp,\n",
       "  6: fare: optional double,\n",
       "  7: pickup_location: optional string,\n",
       "  8: dropoff_location: optional string\n",
       "),\n",
       "partition by: [pickup_time],\n",
       "sort order: [],\n",
       "snapshot: null"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define schema using NestedField\n",
    "\n",
    "# ❗ Iceberg requires all fields to have stable, explicit IDs.\n",
    "# This is critical for schema evolution and tracking changes over time.\n",
    "# That's why we use NestedField() — each field has:\n",
    "# - field_id: required, stable numeric ID\n",
    "# - name: field name\n",
    "# - field_type: Iceberg data type\n",
    "# - required: whether the field is NOT NULL\n",
    "\n",
    "rides_schema = Schema(\n",
    "    NestedField(field_id=1, name=\"ride_id\", field_type=UUIDType(), required=True),\n",
    "    NestedField(field_id=2, name=\"driver_id\", field_type=StringType(), required=False),\n",
    "    NestedField(field_id=3, name=\"customer_id\", field_type=StringType(), required=False),\n",
    "    NestedField(field_id=4, name=\"pickup_time\", field_type=TimestampType(), required=False),\n",
    "    NestedField(field_id=5, name=\"dropoff_time\", field_type=TimestampType(), required=False),\n",
    "    NestedField(field_id=6, name=\"fare\", field_type=DoubleType(), required=False),\n",
    "    NestedField(field_id=7, name=\"pickup_location\", field_type=StringType(), required=False),\n",
    "    NestedField(field_id=8, name=\"dropoff_location\", field_type=StringType(), required=False)\n",
    ")\n",
    "\n",
    "from pyiceberg.partitioning import PartitionSpec\n",
    "\n",
    "rides_partition_spec = PartitionSpec(\n",
    "    fields=[\n",
    "        PartitionField(\n",
    "            source_id=4,\n",
    "            field_id=1000,\n",
    "            transform=\"identity\",\n",
    "            name=\"pickup_time\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Drop if exists (optional)\n",
    "# try:\n",
    "#     catalog.drop_table(identifier=f\"{namespace}.rides\")\n",
    "# except NoSuchTableError:\n",
    "#     pass\n",
    "\n",
    "catalog.create_table(\n",
    "    identifier=f\"{namespace}.rides\",\n",
    "    schema=rides_schema,\n",
    "    partition_spec=rides_partition_spec\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fe75702-a73d-442e-8a83-91b2d1cf0525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drivers(\n",
       "  1: driver_id: required string,\n",
       "  2: full_name: optional string,\n",
       "  3: city: optional string,\n",
       "  4: active: optional boolean,\n",
       "  5: rating: optional int,\n",
       "  6: last_updated: optional timestamp\n",
       "),\n",
       "partition by: [city],\n",
       "sort order: [],\n",
       "snapshot: null"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drivers_schema = Schema(\n",
    "    NestedField(field_id=1, name=\"driver_id\", field_type=StringType(), required=True),\n",
    "    NestedField(field_id=2, name=\"full_name\", field_type=StringType(), required=False),\n",
    "    NestedField(field_id=3, name=\"city\", field_type=StringType(), required=False),\n",
    "    NestedField(field_id=4, name=\"active\", field_type=BooleanType(), required=False),\n",
    "    NestedField(field_id=5, name=\"rating\", field_type=IntegerType(), required=False),\n",
    "    NestedField(field_id=6, name=\"last_updated\", field_type=TimestampType(), required=False)\n",
    ")\n",
    "\n",
    "# Partition by city (field_id=3)\n",
    "drivers_partition_spec = PartitionSpec(\n",
    "    fields=[\n",
    "        PartitionField(\n",
    "            source_id=3,\n",
    "            field_id=1001,\n",
    "            transform=\"identity\",\n",
    "            name=\"city\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the table\n",
    "catalog.create_table(\n",
    "    identifier=f\"{namespace}.drivers\",\n",
    "    schema=drivers_schema,\n",
    "    partition_spec=drivers_partition_spec\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57587b82-7127-4cde-a687-7565dc432278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "payments(\n",
       "  1: payment_id: required uuid,\n",
       "  2: ride_id: optional string,\n",
       "  3: customer_id: optional string,\n",
       "  4: amount: optional decimal(10, 2),\n",
       "  5: status: optional string,\n",
       "  6: timestamp: optional timestamp\n",
       "),\n",
       "partition by: [timestamp],\n",
       "sort order: [],\n",
       "snapshot: null"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payments_schema = Schema(\n",
    "    NestedField(field_id=1, name=\"payment_id\", field_type=UUIDType(), required=True),\n",
    "    NestedField(field_id=2, name=\"ride_id\", field_type=StringType(), required=False),\n",
    "    NestedField(field_id=3, name=\"customer_id\", field_type=StringType(), required=False),\n",
    "    NestedField(field_id=4, name=\"amount\", field_type=DecimalType(precision=10, scale=2), required=False),\n",
    "    NestedField(field_id=5, name=\"status\", field_type=StringType(), required=False),  # e.g. \"paid\", \"refunded\"\n",
    "    NestedField(field_id=6, name=\"timestamp\", field_type=TimestampType(), required=False)\n",
    ")\n",
    "\n",
    "# Partition by 'timestamp' (field_id=6)\n",
    "payments_partition_spec = PartitionSpec(\n",
    "    fields=[\n",
    "        PartitionField(\n",
    "            source_id=6,\n",
    "            field_id=1002,\n",
    "            transform=\"identity\",\n",
    "            name=\"timestamp\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "catalog.create_table(\n",
    "    identifier=f\"{namespace}.payments\",\n",
    "    schema=payments_schema,\n",
    "    partition_spec=payments_partition_spec\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ecf260-0aad-4c62-83cd-285604e791f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3fec48-6179-48db-9323-061c7fe137cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "from pyiceberg.catalog import load_rest\n",
    "from pyiceberg.exceptions import NamespaceAlreadyExistsError, TableAlreadyExistsError\n",
    "import boto3\n",
    "\n",
    "aws_access_key_id = os.environ[\"AWS_ACCESS_KEY_ID\"] # admin\n",
    "aws_secret_access_key = os.environ[\"AWS_SECRET_ACCESS_KEY\"] # password\n",
    "\n",
    "catalog = load_rest(\n",
    "    name=\"rest\",\n",
    "    conf = {\n",
    "        \"uri\": \"http://rest:8181/\",\n",
    "        \"s3.endpoint\": \"http://minio:9000\",\n",
    "        \"s3.access-key\": aws_access_key_id,\n",
    "        \"s3.secret-key\": aws_secret_access_key\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create a S3 \"mocked\" client with iceberg user credentials\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://minio:9000\",  # ✅ Use the container name\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "\n",
    "namespace = \"poc_new\"\n",
    "try:\n",
    "    catalog.create_namespace(namespace)\n",
    "except NamespaceAlreadyExistsError as e:\n",
    "    pass\n",
    "\n",
    "namespaces = catalog.list_namespaces()\n",
    "print(\"Namespaces:\", namespaces)\n",
    "\n",
    "def list_blobs(bucket=None):\n",
    "    \"\"\"\n",
    "    Lists blobs (objects) in a specific S3 bucket or in all buckets.\n",
    "\n",
    "    Parameters:\n",
    "        bucket (str, optional): Bucket name. If not provided, lists objects in all buckets.\n",
    "    \"\"\"\n",
    "    if bucket:\n",
    "        print(f\"\\nObjects in bucket: {bucket}\")\n",
    "        _print_bucket_objects(bucket)\n",
    "    else:\n",
    "        buckets = s3.list_buckets()[\"Buckets\"]\n",
    "        for b in buckets:\n",
    "            bucket_name = b[\"Name\"]\n",
    "            print(f\"\\nObjects in bucket: {bucket_name}\")\n",
    "            _print_bucket_objects(bucket_name)\n",
    "\n",
    "\n",
    "def _print_bucket_objects(bucket_name):\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "    if \"Contents\" in response:\n",
    "        for obj in response[\"Contents\"]:\n",
    "            print(f\" - {obj['Key']}\")\n",
    "    else:\n",
    "        print(\" (Empty)\")\n",
    "\n",
    "list_blobs()\n",
    "\n",
    "df = pa.Table.from_pylist(\n",
    "    [\n",
    "        {\"lat\": 52.371807, \"long\": 4.896029},\n",
    "        {\"lat\": 52.387386, \"long\": 4.646219},\n",
    "        {\"lat\": 52.078663, \"long\": 4.288788},\n",
    "    ],\n",
    ")\n",
    "schema = df.schema\n",
    "\n",
    "table_name = \"coordinates\"\n",
    "table_identifier = f\"{namespace}.{table_name}\"\n",
    "\n",
    "try:\n",
    "    table = catalog.create_table(\n",
    "        identifier=table_identifier,\n",
    "        schema=schema,\n",
    "    )\n",
    "except TableAlreadyExistsError as e:\n",
    "    pass\n",
    "\n",
    "table = catalog.load_table(table_identifier)\n",
    "table.append(df)\n",
    "\n",
    "result = table.scan().to_arrow()\n",
    "print(result)\n",
    "\n",
    "list_blobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ca8493-19d7-4b62-a72b-2dcc24328b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a S3 \"mocked\" client with iceberg user credentials\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://minio:9000\",  # ✅ Use the container name\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a20113-91e7-4571-b9bb-2ce3ac88b826",
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace = \"poc_new\"\n",
    "try:\n",
    "    catalog.create_namespace(namespace)\n",
    "except NamespaceAlreadyExistsError as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d66b663-0f94-4e8b-8f06-731a55f26e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespaces: [('poc_new',)]\n"
     ]
    }
   ],
   "source": [
    "namespaces = catalog.list_namespaces()\n",
    "print(\"Namespaces:\", namespaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d4ec01-436f-4f5c-8643-42f91868007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_blobs(bucket=None):\n",
    "    \"\"\"\n",
    "    Lists blobs (objects) in a specific S3 bucket or in all buckets.\n",
    "\n",
    "    Parameters:\n",
    "        bucket (str, optional): Bucket name. If not provided, lists objects in all buckets.\n",
    "    \"\"\"\n",
    "    if bucket:\n",
    "        print(f\"\\nObjects in bucket: {bucket}\")\n",
    "        _print_bucket_objects(bucket)\n",
    "    else:\n",
    "        buckets = s3.list_buckets()[\"Buckets\"]\n",
    "        for b in buckets:\n",
    "            bucket_name = b[\"Name\"]\n",
    "            print(f\"\\nObjects in bucket: {bucket_name}\")\n",
    "            _print_bucket_objects(bucket_name)\n",
    "\n",
    "\n",
    "def _print_bucket_objects(bucket_name):\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "    if \"Contents\" in response:\n",
    "        for obj in response[\"Contents\"]:\n",
    "            print(f\" - {obj['Key']}\")\n",
    "    else:\n",
    "        print(\" (Empty)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bc6f896-35b5-4c9f-a1ab-9d551847aabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objects in bucket: warehouse\n",
      " (Empty)\n"
     ]
    }
   ],
   "source": [
    "list_blobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddb85b42-e823-486a-b480-03e04c1d0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pa.Table.from_pylist(\n",
    "    [\n",
    "        {\"lat\": 52.371807, \"long\": 4.896029},\n",
    "        {\"lat\": 52.387386, \"long\": 4.646219},\n",
    "        {\"lat\": 52.078663, \"long\": 4.288788},\n",
    "    ],\n",
    ")\n",
    "schema = df.schema\n",
    "\n",
    "table_name = \"coordinates\"\n",
    "table_identifier = f\"{namespace}.{table_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2af0715f-791f-4c14-b3e2-ff8f5b567415",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    table = catalog.create_table(\n",
    "        identifier=table_identifier,\n",
    "        schema=schema,\n",
    "    )\n",
    "except TableAlreadyExistsError as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a20b52-0674-4595-8859-5c0db50f14e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = catalog.load_table(table_identifier)\n",
    "table.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f11903d-c5be-486c-a1ef-bde9fb571e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Table\n",
      "lat: double\n",
      "long: double\n",
      "----\n",
      "lat: [[52.371807,52.387386,52.078663]]\n",
      "long: [[4.896029,4.646219,4.288788]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pyiceberg/avro/decoder.py:185: UserWarning: Falling back to pure Python Avro decoder, missing Cython implementation\n",
      "  warnings.warn(\"Falling back to pure Python Avro decoder, missing Cython implementation\")\n"
     ]
    }
   ],
   "source": [
    "result = table.scan().to_arrow()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "089ef9ed-32df-4a60-b88b-bf0ec737981d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objects in bucket: warehouse\n",
      " - poc_new/coordinates/data/00000-0-977d2bf6-fc86-443a-bd63-5e7b06caffbd.parquet\n",
      " - poc_new/coordinates/metadata/00000-ab97f938-d7c6-4d14-8142-eb88f3da9569.metadata.json\n",
      " - poc_new/coordinates/metadata/00001-565668f6-fe20-4ee2-98f6-0fc10bba87c7.metadata.json\n",
      " - poc_new/coordinates/metadata/977d2bf6-fc86-443a-bd63-5e7b06caffbd-m0.avro\n",
      " - poc_new/coordinates/metadata/snap-1981489265837032690-0-977d2bf6-fc86-443a-bd63-5e7b06caffbd.avro\n"
     ]
    }
   ],
   "source": [
    "list_blobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f593d7-5d7f-4852-a2ac-e9034b880dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
