{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cabc966-dc04-4d1b-92af-b4de1324dab4",
   "metadata": {},
   "source": [
    "### MinIO explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6925cf3-92dc-4185-9ee7-53fc56bed26d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# These come from your docker-compose env vars\n",
    "aws_access_key_id = os.environ[\"AWS_ACCESS_KEY_ID\"]     # \"admin\"\n",
    "aws_secret_access_key = os.environ[\"AWS_SECRET_ACCESS_KEY\"]  # \"password\"\n",
    "aws_region = os.environ[\"AWS_REGION\"] # us-east-1\n",
    "\n",
    "# Mocked S3 client that connects to local MinIO\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://minio:9000\",  # Local MinIO service\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    region_name=aws_region\n",
    ")\n",
    "\n",
    "# Create a bucket\n",
    "s3.create_bucket(Bucket=\"poc\")\n",
    "\n",
    "# Create a blob (upload a file)\n",
    "s3.put_object(Bucket=\"poc\", Key=\"demo.txt\", Body=b\"Hello, Iceberg!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9b5fb31f-d2ae-4f1a-b2ab-06611db6f71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found object: demo.txt\n"
     ]
    }
   ],
   "source": [
    "# List all the blobs\n",
    "\n",
    "response = s3.list_objects_v2(Bucket=\"poc\")\n",
    "for obj in response.get(\"Contents\", []):\n",
    "    print(f\"Found object: {obj['Key']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "062b77f6-284d-4710-b1f1-051945aec80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Iceberg!\n"
     ]
    }
   ],
   "source": [
    "# Read the blob\n",
    "\n",
    "response = s3.get_object(Bucket=\"poc\", Key=\"demo.txt\")\n",
    "print(response[\"Body\"].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "03613e3a-8759-4993-afaf-debb3268a1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean it up\n",
    "\n",
    "# Delete blob\n",
    "s3.delete_object(Bucket=\"poc\", Key=\"demo.txt\")\n",
    "\n",
    "# Delete bucket\n",
    "s3.delete_bucket(Bucket=\"poc\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21232b4-f564-41e1-8c0a-07b977a09071",
   "metadata": {},
   "source": [
    "### Iceberg time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d1371524-5cd3-4000-b685-ba596a03cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.catalog import load_rest\n",
    "\n",
    "catalog = load_rest(\n",
    "    name=\"rest\",\n",
    "    conf = {\n",
    "        \"uri\": \"http://rest:8181/\",\n",
    "        \"s3.endpoint\": \"http://minio:9000\",\n",
    "        \"s3.access-key\": aws_access_key_id,\n",
    "        \"s3.secret-key\": aws_secret_access_key\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f406b19a-ba89-4dbe-bda1-dd3d83a428e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyiceberg.exceptions import NamespaceAlreadyExistsError\n",
    "\n",
    "namespace = \"rideshare\"\n",
    "\n",
    "try:\n",
    "    catalog.create_namespace(namespace)\n",
    "except NamespaceAlreadyExistsError:\n",
    "    pass  # It's fine if it already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "deec08c7-d43f-490c-9837-de73f497eb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespaces: [('rideshare',)]\n"
     ]
    }
   ],
   "source": [
    "namespaces = catalog.list_namespaces()\n",
    "print(\"Namespaces:\", namespaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "defddb68-d600-48f9-9da0-2c66f59b7866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, imports\n",
    "from pyiceberg.schema import Schema\n",
    "from pyiceberg.types import (\n",
    "    NestedField, StringType, DateType, DoubleType\n",
    ")\n",
    "from pyiceberg.partitioning import PartitionSpec, PartitionField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2268b6f9-b475-4bb5-9ce2-c8bf370992d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùó Iceberg requires all fields to have stable, explicit IDs.\n",
    "# This is critical for schema evolution and tracking changes over time.\n",
    "# That's why we use NestedField() ‚Äî each field has:\n",
    "# - field_id: required, stable numeric ID\n",
    "# - name: field name\n",
    "# - field_type: Iceberg data type\n",
    "# - required: whether the field is NOT NULL\n",
    "\n",
    "rides_schema = Schema(\n",
    "    NestedField(field_id=1, name=\"ride_id\", field_type=StringType(), required=True),\n",
    "    NestedField(field_id=2, name=\"driver_id\", field_type=StringType()),\n",
    "    NestedField(field_id=3, name=\"customer_id\", field_type=StringType()),\n",
    "    NestedField(field_id=4, name=\"pickup_time\", field_type=DateType()),\n",
    "    NestedField(field_id=5, name=\"dropoff_time\", field_type=DateType()),\n",
    "    NestedField(field_id=6, name=\"fare\", field_type=DoubleType()),\n",
    "    NestedField(field_id=7, name=\"pickup_location\", field_type=StringType()),\n",
    "    NestedField(field_id=8, name=\"dropoff_location\", field_type=StringType()),\n",
    "    NestedField(field_id=9, name=\"status\", field_type=StringType()),\n",
    "    NestedField(field_id=10, name=\"pickup_day\", field_type=DateType())  # üëà NEW column for partitioning\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a723efd3-9f8d-4aaa-9e85-4a75a385366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_partition_spec = PartitionSpec(\n",
    "    fields=[\n",
    "        PartitionField(\n",
    "            source_id=10,      # üëà pickup_day's field ID\n",
    "            field_id=1000,     # unique ID for this partition\n",
    "            transform=\"identity\",\n",
    "            name=\"pickup_day\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9d3ba4da-eef6-483f-9fdb-330a0e7e3b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rides(\n",
       "  1: ride_id: required string,\n",
       "  2: driver_id: optional string,\n",
       "  3: customer_id: optional string,\n",
       "  4: pickup_time: optional date,\n",
       "  5: dropoff_time: optional date,\n",
       "  6: fare: optional double,\n",
       "  7: pickup_location: optional string,\n",
       "  8: dropoff_location: optional string,\n",
       "  9: status: optional string,\n",
       "  10: pickup_day: optional date\n",
       "),\n",
       "partition by: [pickup_day],\n",
       "sort order: [],\n",
       "snapshot: null"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# catalog.drop_table(f\"{namespace}.rides\")\n",
    "\n",
    "catalog.create_table(\n",
    "    identifier=f\"{namespace}.rides\",\n",
    "    schema=rides_schema,\n",
    "    partition_spec=rides_partition_spec\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ce808d95-77d6-4267-b64c-0e150130cdb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "response = s3.list_objects_v2(Bucket=\"warehouse\", Prefix=\"rideshare/rides/metadata/\")\n",
    "\n",
    "for obj in response.get(\"Contents\", []):\n",
    "    obj_name = obj[\"Key\"]\n",
    "    print(f\"Found file: {obj_name}\")\n",
    "    \n",
    "    if obj_name.endswith(\"metadata.json\"):\n",
    "        response = s3.get_object(Bucket=\"warehouse\", Key=obj_name)\n",
    "        content = response[\"Body\"].read().decode()\n",
    "        metadata = json.loads(content)\n",
    "        \n",
    "        print(\"\\n--- Parsed metadata.json ---\\n\")\n",
    "        print(json.dumps(metadata, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "00c834af-50b8-49a6-be1b-a1c5711ce8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate sample data\n",
    "import pandas as pd\n",
    "from uuid import uuid4\n",
    "from datetime import datetime\n",
    "\n",
    "# Sample data\n",
    "df = pd.DataFrame([\n",
    "    {\n",
    "        \"ride_id\": str(uuid4()),  # use string UUID\n",
    "        \"driver_id\": \"driver_001\",\n",
    "        \"customer_id\": \"cust_001\",\n",
    "        \"pickup_time\": datetime(2025, 2, 1, 8, 30).date(),\n",
    "        \"dropoff_time\": datetime(2025, 2, 1, 8, 50).date(),\n",
    "        \"fare\": 23.5,\n",
    "        \"pickup_location\": \"Downtown\",\n",
    "        \"dropoff_location\": \"Airport\",\n",
    "        \"status\": \"completed\"\n",
    "    }\n",
    "])\n",
    "\n",
    "df[\"pickup_day\"] = df[\"pickup_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "de2b9645-e147-403c-bdc0-00e2eb8133ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2. Convert it to Arrow table.\n",
    "import pyarrow as pa\n",
    "\n",
    "# Arrow schema\n",
    "schema = pa.schema([\n",
    "    pa.field(\"ride_id\", pa.string(), nullable=False),\n",
    "    (\"driver_id\", pa.string()),\n",
    "    (\"customer_id\", pa.string()),\n",
    "    (\"pickup_time\", pa.date32()),\n",
    "    (\"dropoff_time\", pa.date32()),\n",
    "    (\"fare\", pa.float64()),\n",
    "    (\"pickup_location\", pa.string()),\n",
    "    (\"dropoff_location\", pa.string()),\n",
    "    (\"status\", pa.string()),\n",
    "    (\"pickup_day\", pa.date32())\n",
    "])\n",
    "\n",
    "# Convert to Arrow Table\n",
    "table = pa.Table.from_pandas(df, schema=schema, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "098c670c-2845-4256-985f-e64bea243f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Data appended to Iceberg table: rideshare.rides\n"
     ]
    }
   ],
   "source": [
    "# 3. Register it with the Iceberg table\n",
    "table_identifier = \"rideshare.rides\"\n",
    "\n",
    "# Just load the table and append the data\n",
    "iceberg_table = catalog.load_table(table_identifier)\n",
    "iceberg_table.append(table)\n",
    "\n",
    "print(f\"üìå Data appended to Iceberg table: {table_identifier}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f8cd36-c47d-45a3-b3c7-10ba054c2d7e",
   "metadata": {},
   "source": [
    "#### Let's try to add new field in pyiceberg, without changing the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1fa60550-bee8-40d1-ba28-b2b7fd5ab091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Add new field\n",
    "df[\"tip_amount\"] = 3.25\n",
    "\n",
    "# 2. Update the Arrow schema to include the new column:\n",
    "schema_tip = pa.schema([\n",
    "    pa.field(\"ride_id\", pa.string(), nullable=False),\n",
    "    pa.field(\"driver_id\", pa.string()),\n",
    "    pa.field(\"customer_id\", pa.string()),\n",
    "    pa.field(\"pickup_time\", pa.date32()),\n",
    "    pa.field(\"dropoff_time\", pa.date32()),\n",
    "    pa.field(\"fare\", pa.float64()),\n",
    "    pa.field(\"pickup_location\", pa.string()),\n",
    "    pa.field(\"dropoff_location\", pa.string()),\n",
    "    pa.field(\"status\", pa.string()),\n",
    "    pa.field(\"pickup_day\", pa.date32()),\n",
    "    pa.field(\"tip_amount\", pa.float64())  # New field\n",
    "])\n",
    "\n",
    "table = pa.Table.from_pandas(df, schema=schema_tip, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "32fa82ec-8812-47fc-adef-0935b9919a96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot append data with different schema!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    iceberg_table = catalog.load_table(\"rideshare.rides\")\n",
    "    iceberg_table.append(table)\n",
    "except ValueError:\n",
    "    print(\"Cannot append data with different schema!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0d1458d8-afdf-4cb6-8ec0-daf6972c2a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns a connected cursor and conn so you can reuse it flexibly.\n",
    "import mysql.connector\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def starrocks_cursor(host=\"starrocks-fe\", port=9030, user=\"root\", password=\"\"):\n",
    "    conn = mysql.connector.connect(\n",
    "        host=host,\n",
    "        port=port,\n",
    "        user=user,\n",
    "        password=password\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        yield cursor\n",
    "        conn.commit()\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "28e5fec0-36d4-43ca-81b1-78beea4fb597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [(1,)]\n"
     ]
    }
   ],
   "source": [
    "# Test connection\n",
    "with starrocks_cursor() as cursor:\n",
    "    cursor.execute(\"SELECT 1;\")\n",
    "    print(\"Result:\", cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8017c463-d255-4649-aac8-ed35e8064de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Iceberg catalog `demo` registered.\n"
     ]
    }
   ],
   "source": [
    "# Register catalog\n",
    "\n",
    "sql_query = f\"\"\"\n",
    "CREATE EXTERNAL CATALOG 'demo'\n",
    "COMMENT \"External catalog to Apache Iceberg on MinIO\"\n",
    "PROPERTIES\n",
    "(\n",
    "  \"type\"=\"iceberg\",  -- defines this as an iceberg catalog\n",
    "  \"iceberg.catalog.type\"=\"rest\",  -- uses the rest catalog backend\n",
    "  \"iceberg.catalog.uri\"=\"http://iceberg-rest:8181\",  -- rest catalog endpoint\n",
    "  \"iceberg.catalog.warehouse\"=\"warehouse\",  -- root path in s3/minio\n",
    "  \"aws.s3.access_key\"=\"{os.environ[\"AWS_ACCESS_KEY_ID\"]}\",  -- minio access key\n",
    "  \"aws.s3.secret_key\"=\"{os.environ[\"AWS_SECRET_ACCESS_KEY\"]}\",  -- minio secret key\n",
    "  \"aws.s3.endpoint\"=\"http://minio:9000\",  -- minio api endpoint\n",
    "  \"aws.s3.enable_path_style_access\"=\"true\",  -- required for minio compatibility\n",
    "  \"client.factory\"=\"com.starrocks.connector.iceberg.IcebergAwsClientFactory\"  -- tells starrocks to use aws-style s3 client\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with starrocks_cursor() as cursor:\n",
    "    cursor.execute(sql_query)\n",
    "    print(\"‚úÖ Iceberg catalog `demo` registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0dbb57e6-5429-4fc6-b54e-0adc86f93539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('default_catalog', 'Internal', \"An internal catalog contains this cluster's self-managed tables.\"), ('demo', 'Iceberg', 'External catalog to Apache Iceberg on MinIO')]\n"
     ]
    }
   ],
   "source": [
    "with starrocks_cursor() as cursor:\n",
    "    cursor.execute(\"SHOW CATALOGS;\")\n",
    "    print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6cb0e367-ce75-472a-adfb-18eb2d8fb11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Catalog 'demo' deleted.\n"
     ]
    }
   ],
   "source": [
    "# with starrocks_cursor() as cursor:\n",
    "#     cursor.execute(\"drop catalog demo;\")\n",
    "#     print(\"üóëÔ∏è Catalog 'demo' deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "49abdf7e-8ac3-4bd7-aeaf-5a86b1c3da8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('d569cc54-ea35-4e78-8cb9-411cbce02a85', 'driver_001', 'cust_001', datetime.date(2025, 2, 1), datetime.date(2025, 2, 1), 23.5, 'Downtown', 'Airport', 'completed', datetime.date(2025, 2, 1))]\n"
     ]
    }
   ],
   "source": [
    "with starrocks_cursor() as cursor:\n",
    "    cursor.execute(\"SELECT * FROM demo.rideshare.rides;\")\n",
    "    print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "78c2c66b-9c99-4fcb-a0a6-5654904510b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Row inserted.\n"
     ]
    }
   ],
   "source": [
    "# Insert new record\n",
    "with starrocks_cursor() as cursor:\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO demo.rideshare.rides \n",
    "        VALUES (\n",
    "            '00000000-0000-0000-0000-000000000999',  -- ride_id\n",
    "            'driver_demo',                          -- driver_id\n",
    "            'customer_demo',                        -- customer_id\n",
    "            '2025-06-01 10:00:00',                  -- pickup_time\n",
    "            '2025-06-01 10:15:00',                  -- dropoff_time\n",
    "            12.50,                                  -- fare\n",
    "            'Downtown',                             -- pickup_location\n",
    "            'Uptown',                               -- dropoff_location\n",
    "            'completed',                            -- status\n",
    "            '2025-06-01'                            -- pickup_day\n",
    "        );\n",
    "    \"\"\")\n",
    "    print(\"‚úÖ Row inserted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dbcfe2e0-20e2-426c-8b39-3719ec37a557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('00000000-0000-0000-0000-000000000999', 'driver_demo', 'customer_demo', datetime.date(2025, 6, 1), datetime.date(2025, 6, 1), 12.5, 'Downtown', 'Uptown', 'completed', datetime.date(2025, 6, 1)), ('d569cc54-ea35-4e78-8cb9-411cbce02a85', 'driver_001', 'cust_001', datetime.date(2025, 2, 1), datetime.date(2025, 2, 1), 23.5, 'Downtown', 'Airport', 'completed', datetime.date(2025, 2, 1))]\n"
     ]
    }
   ],
   "source": [
    "with starrocks_cursor() as cursor:\n",
    "    cursor.execute(\"SELECT * FROM demo.rideshare.rides;\")\n",
    "    print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a825dbf6-c1fc-4a62-bdc6-7a192d1fa8f9",
   "metadata": {},
   "source": [
    "#### Let's try to add new record in pyiceberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12dd2a5e-3f26-40b9-9035-6ce3c2ec393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "\n",
    "df = df.drop(columns=[\"tip_amount\"])\n",
    "\n",
    "# New record with tip_amount\n",
    "new_record = {\n",
    "    \"ride_id\": str(uuid4()),\n",
    "    \"driver_id\": \"driver_002\",\n",
    "    \"customer_id\": \"cust_002\",\n",
    "    \"pickup_time\": datetime(2025, 2, 2, 9, 0).date(),\n",
    "    \"dropoff_time\": datetime(2025, 2, 2, 9, 25).date(),\n",
    "    \"fare\": 18.75,\n",
    "    \"pickup_location\": \"Suburbs\",\n",
    "    \"dropoff_location\": \"City Center\",\n",
    "    \"status\": \"completed\",\n",
    "    \"pickup_day\": datetime(2025, 2, 2).date(),\n",
    "}\n",
    "\n",
    "# Append to existing DataFrame\n",
    "df = pd.concat([df, pd.DataFrame([new_record])], ignore_index=True)\n",
    "\n",
    "# convert\n",
    "table = pa.Table.from_pandas(df, schema=schema, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1bba875e-bd08-4350-bf80-21c0a5c0049f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßæ Data without tip_amount appended to Iceberg table.\n"
     ]
    }
   ],
   "source": [
    "iceberg_table = catalog.load_table(\"rideshare.rides\")\n",
    "iceberg_table.append(table)\n",
    "\n",
    "print(\"üßæ Data without tip_amount appended to Iceberg table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee0a28-d199-4df9-99ac-ce7eb6bebdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with starrocks_cursor() as cursor:\n",
    "    cursor.execute(\"SELECT * FROM demo.rideshare.rides;\")\n",
    "    print(cursor.fetchall())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
